{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d08ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41160191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (569, 30), Labels shape: (569,)\n",
      "Column names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print(f\"Data shape: {X.shape}, Labels shape: {y.shape}\")\n",
    "print(\"Column names:\", data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de4c40a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d1fa55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34c82f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y predicted is sigmoid(w * x + b), y true is boolean 0 or 1\n",
    "def calculate_logistic_loss(y_predicted, y_true):\n",
    "    eps = 1e-10\n",
    "    return -np.mean(y_true * np.log(y_predicted + eps) + (1 - y_true) * np.log(1 - y_predicted + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bba63b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean((y_pred >= 0.5) == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38bd46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionCustom:\n",
    "    def __init__(self, lr=0.01, iterations=5000, reg_lambda=0.0):\n",
    "        self.lr = lr\n",
    "        self.iterations = iterations\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.loss_history = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            pred = np.dot(X, self.w) + self.b # x*w + b, prediction is a linear combination\n",
    "            y_pred = sigmoid(pred) # apply sigmoid to get probabilities\n",
    "\n",
    "            # gradients\n",
    "            dw = ((1 / n_samples) * np.dot(X.T, (y_pred - y))) + (self.reg_lambda / n_samples) * self.w # L2 regularization\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            # update\n",
    "            self.w -= self.lr * dw\n",
    "            self.b -= self.lr * db\n",
    "            loss = calculate_logistic_loss(y_pred, y)\n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "    # return estimated probs for class 1\n",
    "    def predict_proba(self, X):\n",
    "        return sigmoid(np.dot(X, self.w) + self.b)\n",
    "\n",
    "    # return class labels 0 or 1\n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X) >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0ef14bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMW81\\AppData\\Local\\Temp\\ipykernel_37064\\3196251242.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy w/o no regularization: 0.956140350877193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMW81\\AppData\\Local\\Temp\\ipykernel_37064\\3196251242.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for poly degree 2 w/o regularization: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# polynomial features with degree 2 without reg\n",
    "model = LogisticRegressionCustom(lr=0.01, iterations=3000, reg_lambda=0.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy w/o no regularization:\", accuracy(y_test, y_pred))\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "model_poly = LogisticRegressionCustom(lr=0.01, iterations=3000, reg_lambda=0.0)\n",
    "model_poly.fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred_poly = model_poly.predict(X_test_poly)\n",
    "print(\"Accuracy for poly degree 2 w/o regularization:\", accuracy(y_test, y_pred_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "348297b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMW81\\AppData\\Local\\Temp\\ipykernel_37064\\3196251242.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 - Train Acc=0.9164835164835164, Test Acc=0.956140350877193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMW81\\AppData\\Local\\Temp\\ipykernel_37064\\3196251242.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 2 - Train Acc=0.9142857142857143, Test Acc=0.9736842105263158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMW81\\AppData\\Local\\Temp\\ipykernel_37064\\3196251242.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 3 - Train Acc=0.9120879120879121, Test Acc=0.9736842105263158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMW81\\AppData\\Local\\Temp\\ipykernel_37064\\3196251242.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 4 - Train Acc=0.8923076923076924, Test Acc=0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "# polynomial features with degrees 1-4 without reg, increase degree until overfitting happens\n",
    "degrees = [1, 2, 3, 4]\n",
    "for d in degrees:\n",
    "    poly = PolynomialFeatures(degree=d, include_bias=False)\n",
    "    X_train_d = poly.fit_transform(X_train)\n",
    "    X_test_d = poly.transform(X_test)\n",
    "\n",
    "    model_d = LogisticRegressionCustom(lr=0.01, iterations=3000, reg_lambda=0.0)\n",
    "    model_d.fit(X_train_d, y_train)\n",
    "\n",
    "    train_acc = accuracy(y_train, model_d.predict(X_train_d))\n",
    "    test_acc = accuracy(y_test, model_d.predict(X_test_d))\n",
    "\n",
    "    print(f\"Degree {d} - Train Acc={train_acc}, Test Acc={test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f386034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMW81\\AppData\\Local\\Temp\\ipykernel_37064\\3196251242.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg=0.0: Train Acc=0.8923076923076924, Test Acc=0.9385964912280702\n",
      "Reg=0.01: Train Acc=0.9186813186813186, Test Acc=0.9649122807017544\n",
      "Reg=0.1: Train Acc=0.8923076923076924, Test Acc=0.9385964912280702\n",
      "Reg=1.0: Train Acc=0.9142857142857143, Test Acc=0.9649122807017544\n",
      "Reg=10: Train Acc=0.9230769230769231, Test Acc=0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# use reg for degree 4 polynomial features\n",
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "X_train_d4 = poly.fit_transform(X_train)\n",
    "X_test_d4 = poly.transform(X_test)\n",
    "\n",
    "reg_values = [0.0, 0.01, 0.1, 1.0, 10]\n",
    "\n",
    "\n",
    "for reg in reg_values:\n",
    "    model_reg = LogisticRegressionCustom(\n",
    "        lr=0.01, iterations=3000, reg_lambda=reg\n",
    "    )\n",
    "    model_reg.fit(X_train_d4, y_train)\n",
    "\n",
    "    train_acc = accuracy(y_train, model_reg.predict(X_train_d4))\n",
    "    test_acc = accuracy(y_test, model_reg.predict(X_test_d4))\n",
    "\n",
    "    print(f\"Reg={reg}: Train Acc={train_acc}, Test Acc={test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
